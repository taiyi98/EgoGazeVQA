# In the Eye of MLLM

This is the official code of **"In the Eye of MLLM: Benchmarking Egocentric Video Intent Understanding with Gaze-Guided Prompting"**.

## Introduction

This repository contains the official implementation of the project titled **"In the Eye of MLLM: Benchmarking Egocentric Video Intent Understanding with Gaze-Guided Prompting"**.  
It provides the necessary code, models, and instructions to reproduce our experiments and results.

## Repository Structure

├── data/ # Data files and preprocessing scripts ├── models/ # Model architectures and checkpoints ├── scripts/ # Training, evaluation, and utility scripts ├── results/ # Output results and logs ├── README.md # Project description and usage instructions └── requirements.txt # Python dependencies

## Installation

To set up the environment, first install the required Python packages:

pip install -r requirements.txt


Ensure you are using Python 3.8 or above.

## Usage


### Train the Model


